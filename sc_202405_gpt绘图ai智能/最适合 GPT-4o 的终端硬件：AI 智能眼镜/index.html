
            <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta name="description" content="如果 OpenAI 和苹果达成长期合作，GPT-4o 加上苹果 AI 智能眼镜的组合，或许这才是 AI 时代最值得期待的事情。">
                <meta name="keywords" content="最适合 GPT-4o 的终端硬件：AI 智能眼镜, 如果 OpenAI 和苹果达成长期合作，GPT-4o 加上苹果 AI 智能眼镜的组合，或许这才是 AI 时代最值得期待的事情。">
                <meta property="og:title" content="最适合 GPT-4o 的终端硬件：AI 智能眼镜">
                <title>最适合 GPT-4o 的终端硬件：AI 智能眼镜</title>
                <style>.hidden{visibility:hidden;font-size:1px;}</style>
            </head>
            <body>
                <div class="rich_media_wrp" id="img-content">
<h1 class="rich_media_title" id="activity-name">
            
最适合 GPT-4o 的终端硬件：AI 智能眼镜
          </h1>

<div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content" style="visibility: visible;"><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">5月13日，OpenAI 发布了 GPT-4o（“o”代表“omni”）。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">GPT-4o 是 OpenAI 最新的旗舰型号，它接受文本、音频和图像的任意组合作为输入，并生成文本、音频和图像输出的任意组合。<strong>与之前的 GPT-4 相比，GPT-4o 大幅改善了语音交互的延迟，并提高了对图像和音频的理解能力</strong>。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">在 GPT-4o 之前，我们可以使用语音模式与 ChatGPT 交谈。其中，GPT-3.5 的平均延迟为 2.8 秒，GPT-4 的平均延迟为 5.4 秒。而使用 GPT-4o 进行语音交互，平均延迟仅为 0.32 秒。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><strong><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">GPT-4o 之所以能大幅改善语音交互的延迟，是因为它是一个端到端多模态大模型，它所有的输入和输出都由同一个神经网络进行处理</span></strong><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">。过去使用的语音模式则是一个由三个独立模型组成的管道，首先语音转文本模型（Whisper）将输入音频转换为文本，接着 GPT-3.5 或 GPT-4 接收文本并输出文本，最后文本转语音模型（TTS）将该文本转换为音频输出。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-backh="351" data-backw="562" data-cropselx1="0" data-cropselx2="562" data-cropsely1="0" data-cropsely2="351" data-galleryid="" data-imgfileid="100000814" data-ratio="0.625" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/FterKGM7ENMMHBAiaic5KwR1LWoQWygDfhLGHzMHXFykwyEh9LbhPu0DR8OT2wRiaB9123OibBdO4OWl6brZVXTVibA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="20240523_124745_0.jpeg" style="width: 100%;height: auto;"/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;text-align: center;"><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 0.5px;text-align: center;text-wrap: wrap;">GPT-4o 是一个端到端多模态大模型</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(18, 117, 174);"><strong><span style="color: rgb(18, 117, 174);font-size: 16px;letter-spacing: 0.5px;">OpenAI 为什么要发布 GPT-4o</span></strong></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">在以 Llama 3 为代表的开源模型的步步紧逼之下，市场此前认为 OpenAI 可能会尽快发布 GPT-4.5 或 GPT-5 来应对 Llama 3 的挑战。但 OpenAI 却在这个时间点，发布了侧重于语音交互和视觉理解的 GPT-4o，这让很多人感到困惑——为什么 OpenAI 发布的是 GPT-4o，而不是 GPT-4.5 或 GPT-5？</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">更令人费解的是，OpenAI 宣布 GPT-4o 向所有免费用户开放。要知道此前只有 ChatGPT Plus 付费订阅用户才可以使用 GPT-4，而现在所有免费用户都可以使用比 GPT-4 更先进的 GPT-4o 模型，这种做法似乎会削弱 Plus 用户的付费意愿。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">事实上，要理解 OpenAI 为什么要发布 GPT-4o，我们可以将以下三点信息关联起来：（1）GPT-4o 侧重于语音交互和视觉理解；（2）GPT-4o 向所有用户<span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;text-wrap: wrap;">免费</span>开放；（3）苹果最近考虑在 OpenAI 和谷歌之间二选一，选择一家公司为新款 iPhone 提供模型支持，而 OpenAI 则选择在谷歌开发者大会（5月14日）前一天发布 GPT-4o。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">首先，与 GPT-4 相比，GPT-4o 最大的变化在于改善了语音交互的延迟，并提高了对图像和音频的理解能力。<strong>这两项能力（低延迟语音交互、更好的图像和音频理解能力）非常契合智能手机</strong>。例如，在 GPT-4o 的官方演示中，我们可以看到演示人员使用 iPhone 摄像头实时拍摄数学方程的解题过程，并通</span><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">过语音交互让 GPT-4o 来帮助自己得到正确的答案。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><section class="channels_iframe_wrp" style="margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><mp-common-videosnap class="js_uneditable custom_select_card channels_iframe videosnap_video_iframe" data-authiconurl="" data-desc="OpenAI GPT-4o 发布会" data-errortips="" data-from="new" data-headimgurl="http://wx.qlogo.cn/finderhead/Mn5PcRO3b9olqpfQciaUcLQwtmzKcggQUdg8p14S3USY/0" data-height="1080" data-id="export/UzFfAgtgekIEAQAAAAAAXPwEJKXd4AAAAAstQy6ubaLX4KHWvLEZgBPEyKFkDnBGfriEzNPgMIv2pECxRMfrSozyrABw5y_j" data-isdisabled="0" data-mediatype="undefined" data-nickname="3D互联网" data-nonceid="4298935103166215926" data-pluginname="mpvideosnap" data-type="video" data-url="https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqzeJX33WiaKibFzWbic1xz7ZZCfQqEzsPJwusEIIBzhgcKlCso2wib3RKQeIDtFvvS4fVzdc0AOSgaKRQk2WjwYIkiaMw&amp;token=6xykWLEnztJDDNseZNhbFiaIp1Fwft4aEbCmSkaN770DP6E3M1fOQj9Q5iawbcwWhJcZlF1Fr0Ibtm9k5QeCKicULJTickmGI9cRrXsYHc6rZgaSd8TtXJcSGXtiacMlNQXXd&amp;idx=1&amp;dotrans=0&amp;hy=SH&amp;m=&amp;scene=2&amp;uzid=2" data-username="v2_060000231003b20faec8c4e58c1ac6d4c800e432b077bdfe608b3f06459ec0cb14784fea281d@finder" data-width="1920"></mp-common-videosnap></section><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;text-align: center;"><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 0.5px;text-align: center;text-wrap: wrap;">OpenAI GPT-4o 发布会</span><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-backh="316" data-backw="562" data-galleryid="" data-imgfileid="100000821" data-ratio="0.562962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/FterKGM7ENMMHBAiaic5KwR1LWoQWygDfhuCce8CE9kWQD3iaG7qOXggbzib4BMmYgPZucrtopbdhibrZ95nAylEwlg/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="20240523_124746_1.jpeg" style="width: 100%;height: auto;"/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;text-align: center;"><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 0.5px;text-align: center;text-wrap: wrap;">GPT-4o 官方演示</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">其次，GPT-4o 向所有用户免费开放，有助于更多智能手机用户体验 GPT-4o，这能让 OpenAI 在和苹果的谈判中，基于用户口碑获得更多的谈判优势。毕竟在苹果二选一的情况下，对于 OpenAI 来说，全球超过10亿的 iPhone 手机用户是它不能失去的客户群体。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><strong><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">所以 OpenAI 在这个时间点发布 GPT-4o，可能更多是为了促成与苹果的长期合作，以便深度集成到未来的 iPhone 手机中。</span></strong></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(18, 117, 174);"><strong><span style="color: rgb(18, 117, 174);font-size: 16px;letter-spacing: 0.5px;">最适合 GPT-4o 的硬件是智能眼镜</span></strong></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">虽然 GPT-4o 非常契合智能手机，但我们在使用过程中仍然存在痛点。就像我们在 GPT-4o 官方演示中看到的那样，我们需要使用一只手拿着手机拍摄，以便让 GPT-4o 能够看到并理解视觉场景，这导致使用过程缺乏灵活性，并且增加了交互的复杂度。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><strong><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">因此，更适合 GPT-4o 的终端硬件，应该是能够解放我们的双手，让我们在处理复杂任务时拥有最大程度的操作灵活性和便捷度。</span></strong></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">目前有两种硬件方案可供选择。第一种是智能眼镜，智能眼镜配备摄像头、麦克风和扬声器，支持语音交互和图像视频拍摄。第二种是带有摄像头的智能耳机，这是在我们日常佩戴的智能耳机上增配摄像头。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">这两种方案的主要差异在于，智能眼镜的摄像头在正面，智能耳机的摄像头在侧面。<strong>正面的摄像头比侧面的摄像头拥有更大的拍摄角度，也更符合我们的视觉习惯，因此智能眼镜会比带有摄像头的智能耳机更适合 GPT-4o</strong>。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(18, 117, 174);"><strong><span style="color: rgb(18, 117, 174);font-size: 16px;letter-spacing: 0.5px;">AI 智能眼镜已得到市场验证</span></strong></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">在已发布的产品中，最具有代表性的 AI 智能眼镜是 Meta 联合雷朋发布的第二代 Ray-Ban Meta 智能眼镜。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;text-align: center;"><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 0.5px;text-align: center;text-wrap: wrap;">Ray-Ban Meta 智能眼镜</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">就在三周前（4月23日），Meta 在 Ray-Ban Meta 智能眼镜中正式上线了 Llama 3 多模态功能。Llama 3 多模态大模型是一个类似于 GPT-4o 的大模型，它可以配合支持语音交互和图像视频拍摄功能的智能眼镜，来辅助我们解决复杂任务，或者担任我们的随身 AI 助手。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><section class="channels_iframe_wrp" style="margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><mp-common-videosnap class="js_uneditable custom_select_card channels_iframe videosnap_video_iframe" data-authiconurl="" data-desc="Ray-Ban Meta 智能眼镜上线 Llama 3 多模态功能" data-errortips="" data-from="new" data-headimgurl="http://wx.qlogo.cn/finderhead/Mn5PcRO3b9olqpfQciaUcLQwtmzKcggQUdg8p14S3USY/0" data-height="1080" data-id="export/UzFfAgtgekIEAQAAAAAA9bInetYRdQAAAAstQy6ubaLX4KHWvLEZgBPExKFgMVR_P6GEzNPgMIsUVnsceIQKDTI8B5NB3a-P" data-isdisabled="0" data-mediatype="undefined" data-nickname="3D互联网" data-nonceid="1237923833479345639" data-pluginname="mpvideosnap" data-type="video" data-url="https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqz6aibxGaJFXPdWbDFcPiaUvf5pczatwKaHunMlsuj7LntnUdX6AeQwBlRcyZtfBaTp6VDy9fA6txRM8w4BQlLW6qA&amp;token=cztXnd9GyrHibT98Wj509y7eUxxrQ2vT8RafuKmZtzUVQKibJO5vCR4PnamV4YKNPrqNmGCQo01ibvqic4gcvnH6qzkEFBQ9jSLyYyJP0KQwLpiazzSUgiaGib8mrmlRBP7eiaZ9&amp;idx=1&amp;bizid=1023&amp;dotrans=0&amp;hy=SH&amp;m=&amp;scene=2" data-username="v2_060000231003b20faec8c4e58c1ac6d4c800e432b077bdfe608b3f06459ec0cb14784fea281d@finder" data-width="1920"></mp-common-videosnap></section><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;text-align: center;"><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 0.5px;text-align: center;text-wrap: wrap;">Ray-Ban Meta 智能眼镜 + Llama 3 多模态大模型</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><strong><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">目前第二代 Ray-Ban Meta 智能眼镜累计出货量已超过 100 万台，并且处于供不应求的状态</span></strong><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">。其基础款定价 299 美元，折合人民币大概是 2100 元，这其中还包含了雷朋的品牌溢价。显然，以 Ray-Ban Meta 智能眼镜为代表的 AI 智能眼镜已经得到了市场的验证。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">第二代 Ray-Ban Meta 智能眼镜的硬件成本大概是 1200 元，其中采用 4nm 工艺制程的主控芯片高通 AR1 Gen 1，大概占了三分之一，接近 400 元。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">事实上，将高通 AR1 Gen 1 芯片用于 AI 智能眼镜中，明显性能过剩了，因为 AI 智能眼镜完全不需要用到 AR1 Gen 1 芯片中的 3Dof 和双目全彩显示功能。如果将高通 AR1 Gen 1 芯片替换为采用 6nm 工艺制程的恒玄 BES2800 芯片，AI 智能眼镜的硬件成本还能大幅降低。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;"><br/></span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">当然，苹果发布 AI 智能眼镜，一定会采用自研的主控芯片。参考 AirPods 的定价，增加摄像头、镜框等硬件配置的 AI 智能眼镜，价格可能是 AirPods 的两倍，价格区间可能是 2000-4000 元。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">但是，如果大幅采用国产供应链的硬件配置，未来国内品牌基础款 AI 智能眼镜的定价区间很可能是 500-1000 元，这个价格对于大部分人来说都是可以接受的。因此在价格方面，AI 智能眼镜也已具备大规模普及的市场基础。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">接下来，我们重新回归到 OpenAI 与苹果可能达成的战略合作上。很明显，GPT-4o 拥有比 Llama 3 多模态大模型更强大的综合能力，而苹果也拥有非常卓越的消费级终端硬件的设计和运营能力。<strong>如果 OpenAI 和苹果达成长期合作，GPT-4o 加上苹果 AI 智能眼镜的组合，或许这才是 AI 时代最值得期待的事情</strong>。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><strong><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">苹果 AI 智能眼镜的产品形态可能会类似于 Meta 智能眼镜，产品定位类似于 AirPods，作为配件与 iPhone 一起使用</span></strong><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">其实我们不难想象，在 GPT-4o 官方演示的数学方程解题过程中，如果我们佩戴 AI 智能眼镜，通过实时语音与 GPT-4o 交谈，这不就完全可以替代家长辅导孩子作业了吗？当然，AI 智能眼镜的应用场景远不止此，依靠 GPT-4o 强大的视觉理解能力，它还可以帮助我们在现实生活中处理各式各样的复杂任务，比如技能培训、旅游导览、烹饪助手等等。</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><span style="color: rgb(0, 0, 0);font-size: 16px;letter-spacing: 0.5px;">总之，GPT-4o 已经来了，苹果的 AI 智能眼镜还会远吗？</span></p><p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;"><br/></p><section style="display: none;margin-bottom: 0px;"><br/></section><section style="display: none;margin-bottom: 0px;"><br/></section><section style="display: none;margin-bottom: 0px;"><br/></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></div>

</div>
                <p class="hidden">/s?__biz=Mzg3MDg0MDUzOA==&mid=2247484471&idx=1&sn=59356a1845dcff1b14d9c138306a7d03&chksm=ce86e582f9f16c9492807b102d4588be10e344fd612e04557a922ddd5cff019174e71da061e8#rd </p>

            </body>
            </html>
            